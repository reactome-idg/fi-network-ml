{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c6e02a-b1f6-4107-b778-3c02209bad3d",
   "metadata": {},
   "source": [
    "To support the impact score for proteins on pathways, we also analyzed a scRNA-seq dataset downloaded from the tabular project. We did a sysetmatic correlation analysis using BigScale, an R package. The generated correlation data was then selected by choosing the top 0.1% of correlations as described in the original BigScale correlation paper (https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1713-4. The Java code is used to choose these correlations and then perform pathway enriment analysis as shown here: https://github.com/reactome-idg/fi-network-ml/blob/99022e85c2079b445913cdafc637be5ec2c39509/src/main/java/org/reactome/idg/bn/BigScaleCorrelationAnalyzer.java#L51. The basic step is similar to the NLP analysis. Therefore, this notebook is placed in this folder for easy maintenance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177cbdf5-bc99-415d-a5e9-aebedb251237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "# Make sure all width is used to better take the screen space\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3dfe57-5c9d-40c1-ac00-4771fea02511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse functions used for NLP\n",
    "# import sys\n",
    "# sys.path.insert(1, '.')\n",
    "import TopicModelingResultAnalyzer as result_analyzer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Make sure this folder is right\n",
    "dir_name = '/Volumes/ssd/results/reactome-idg/fi-network-ml/impact_analysis/scRNASeq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6b882-0381-4fe0-ae7c-bd0f07ab90b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_file_name = dir_name + '/' + 'tabula_blood_corr_recursive.csv'\n",
    "# The correlation is pair-wise and the file is big. The loading is a quite slow process.\n",
    "# Make sure don't try to reload!\n",
    "cor_df = pd.read_csv(cor_file_name, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467512fa-5c5c-4e6f-b9ea-31310e176a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cor_df.shape)\n",
    "cor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e2ac72-35ab-4cdc-8c67-9f7310a3fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to fix the column names. An issue from R\n",
    "cor_df.columns = cor_df.columns.map(lambda c : c.replace('.', '-'))\n",
    "cor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f43619-b059-4e37-825f-d5796535a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_df.stack().plot.hist(bins=1000)\n",
    "# The distribution is quite positive with the peak around 0.50. This is a little bit unexpected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c569ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = dir_name + \"/../impact_analysis_092121_with_enrichment_092921_with_scRNASeq_082322.txt\"\n",
    "impact_result_df_with_bigscale = pd.read_csv(file_name, sep = '\\t')\n",
    "impact_result_df_with_bigscale.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964c8245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This is a very long process, taking about 17 minutes\n",
    "impact_result_df_with_bigscale['BigScale_FDR_Log10'] = impact_result_df_with_bigscale.BigScale_FDR.map(lambda f : -np.log10(f))\n",
    "print(impact_result_df_with_bigscale.head())\n",
    "df_cor_fdr_bigscale = calculate_correlation(cor_col_name='BigScale_FDR_Log10', impact_result_df_selected=impact_result_df_with_bigscale)\n",
    "file_name = dir_name + '/df_cor_fdr_bigscale_113022.csv'\n",
    "# file_name = dir_name + '/df_cor_fdr_bigscale_082322.csv'\n",
    "df_cor_fdr_bigscale.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa60543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell runs for about 30 minutes\n",
    "df_cor_average_activation_bigscale = calculate_correlation(cor_col_name='BigScale_FDR_Log10', \n",
    "                                                           impact_col_name='Average_Activation',\n",
    "                                                           impact_result_df_selected=impact_result_df_with_bigscale)\n",
    "# file_name = dir_name + '/df_cor_average_activation_bigscale_082322.csv'\n",
    "file_name = dir_name + '/df_cor_average_activation_bigscale_113022.csv'\n",
    "df_cor_average_activation_bigscale.to_csv(file_name)\n",
    "df_cor_average_inhibition_bigscale = calculate_correlation(cor_col_name='BigScale_FDR_Log10', \n",
    "                                                           impact_col_name='Average_Inhibition',\n",
    "                                                           impact_result_df_selected=impact_result_df_with_bigscale)\n",
    "file_name = dir_name + '/df_cor_average_inhibition_bigscale_110322.csv'\n",
    "# file_name = dir_name + '/df_cor_average_inhibition_bigscale_082322.csv'\n",
    "df_cor_average_inhibition_bigscale.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b1728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load these results without re-clculation, which is very long\n",
    "file_name = dir_name + '/df_cor_fdr_bigscale_113022.csv'\n",
    "df_cor_fdr_bigscale = pd.read_csv(file_name)\n",
    "file_name = dir_name + '/df_cor_average_activation_bigscale_113022.csv'\n",
    "df_cor_average_activation_bigscale = pd.read_csv(file_name)\n",
    "file_name = dir_name + '/df_cor_average_inhibition_bigscale_110322.csv'\n",
    "df_cor_average_inhibition_bigscale = pd.read_csv(file_name)\n",
    "\n",
    "# Plots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3)\n",
    "fig.tight_layout(pad=.01)\n",
    "plt.subplots_adjust(bottom=0.2, top=0.95, hspace=0.0)\n",
    "plt.rcParams.update({'font.size': 20})  # This apply to titles only\n",
    "fig.set_figwidth(30)\n",
    "fig.set_figheight(10)\n",
    "g = sns.scatterplot(x = df_cor_fdr_bigscale.Pearson_Cor,\n",
    "                    y = -np.log10(df_cor_fdr_bigscale.Peason_P_Value),\n",
    "                    ax = axes[0])\n",
    "g.set_title('FDR')\n",
    "g = sns.scatterplot(x = df_cor_average_activation_bigscale.Pearson_Cor,\n",
    "                    y = -np.log10(df_cor_average_activation_bigscale.Peason_P_Value), \n",
    "                    ax = axes[1])\n",
    "g.set_title('Average_Activation')\n",
    "g = sns.scatterplot(x = df_cor_average_inhibition_bigscale.Pearson_Cor, \n",
    "                    y = -np.log10(df_cor_average_inhibition_bigscale.Peason_P_Value), \n",
    "                    ax = axes[2])\n",
    "g.set_title('Average_Inhibition')\n",
    "fig.savefig(dir_name + '/df_cor_bigscale_113022_scatter_plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ac8751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For annotation\n",
    "# Following tutorial: https://levelup.gitconnected.com/statistics-on-seaborn-plots-with-statannotations-2bfce0394c00\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import mannwhitneyu\n",
    "def annotate_plot(x,\n",
    "                  y,\n",
    "                  ax,\n",
    "                  pairs,\n",
    "                  pval = None):\n",
    "    annotator = Annotator(ax,\n",
    "                          pairs,\n",
    "                          x=x,\n",
    "                          y=y)\n",
    "    alternative = 'two-sided'\n",
    "    if pairs[0][0] or pairs[0][0] == 'True':\n",
    "        alternative = 'greater'\n",
    "    elif not pairs[0][0] or pairs[0][0] == 'False':\n",
    "        alternative = 'less'\n",
    "    values_1 = y[x == pairs[0][0]]\n",
    "    values_2 = y[x == pairs[0][1]]\n",
    "    # print('Alternative: {}'.format(alternative))\n",
    "    if pval is None:\n",
    "        test_results = mannwhitneyu(values_1, values_2, alternative=alternative)\n",
    "        annotator.set_pvalues([test_results.pvalue])\n",
    "    else:\n",
    "        annotator.set_pvalues([pval])\n",
    "    annotator.annotate()\n",
    "\n",
    "def set_up_subplots(nrow=1, ncols=4):\n",
    "    fig, axes = plt.subplots(nrows=nrow, ncols=ncols)\n",
    "    fig.tight_layout(pad=0.05)\n",
    "    plt.subplots_adjust(left=0.03, right=0.99, bottom=0.1, top=0.95, hspace=0.15, wspace=0.2)\n",
    "    plt.rcParams.update({'font.size': 20})  # This apply to titles only\n",
    "    fig.set_figwidth(36)\n",
    "    fig.set_figheight(12)\n",
    "    return fig, axes\n",
    "\n",
    "def plot_correlation_distribution(cor_df,\n",
    "                                  out_file_name):\n",
    "    # Plot individual score correlations for the manuscript\n",
    "    fig, axes = set_up_subplots(nrow=1, ncols=4)\n",
    "    g = sns.scatterplot(x = 'Pearson_Cor',\n",
    "                        y = -np.log10(cor_df.Peason_P_Value),\n",
    "                        # hue = 'Annotated',\n",
    "                        data = cor_df,\n",
    "                        ax = axes[0])\n",
    "    g.set_xlabel('Pearson Correlation')\n",
    "    g.set_ylabel('-Log10(pValue)')\n",
    "    # left and right dots\n",
    "    cor_df['Is_Cor_Positive'] = cor_df['Pearson_Cor'].map(lambda x : \"True\" if x > 0.0 else \"False\")\n",
    "    cor_df.sort_values(by='Is_Cor_Positive', inplace=True, ascending=True)\n",
    "    # Count\n",
    "    is_cor_positive_count = cor_df.groupby('Is_Cor_Positive').count()\n",
    "    print(\"Plot positive and negative counts:\")\n",
    "    g = sns.barplot(y = 'Pearson_Cor',\n",
    "                    x = is_cor_positive_count.index,\n",
    "                    data = is_cor_positive_count,\n",
    "                    ax = axes[1])\n",
    "    g.set_xlabel('Pearson Correlation > 0')\n",
    "    g.set_ylabel('Counts')\n",
    "    # Need to do proportion\n",
    "    from statsmodels.stats.proportion import proportions_ztest\n",
    "    true_count = is_cor_positive_count['Pearson_Cor']['True']\n",
    "    false_count = is_cor_positive_count['Pearson_Cor']['False']\n",
    "    print(is_cor_positive_count['Pearson_Cor'])\n",
    "    stat, pval = proportions_ztest(true_count, true_count + false_count, 0.50)\n",
    "    annotate_plot(y = is_cor_positive_count.Pearson_Cor,\n",
    "                x = is_cor_positive_count.index,\n",
    "                ax = axes[1],\n",
    "                pairs=[('True', 'False')],\n",
    "                pval = pval)\n",
    "\n",
    "    # Plot pvalues\n",
    "    print(\"Plot p-values:\")\n",
    "    g = sns.boxplot(x = 'Is_Cor_Positive',\n",
    "                    y = -np.log10(cor_df.Peason_P_Value),\n",
    "                    data = cor_df,\n",
    "                    ax = axes[2])\n",
    "    g.set_xlabel('Pearson Correlation > 0')\n",
    "    g.set_ylabel('-Log10(pValue)')\n",
    "    annotate_plot(x=cor_df['Is_Cor_Positive'],\n",
    "                y=-np.log10(cor_df.Peason_P_Value),\n",
    "                ax=axes[2],\n",
    "                pairs=[('True', 'False')])\n",
    "\n",
    "    # Plot correlations\n",
    "    print(\"Plot absolute correlations:\")\n",
    "    g = sns.boxplot(x='Is_Cor_Positive',\n",
    "                    y=np.abs(cor_df['Pearson_Cor']),\n",
    "                    data = cor_df,\n",
    "                    ax = axes[3])\n",
    "    g.set_xlabel('Pearson Correlation > 0')\n",
    "    g.set_ylabel('Absolute Correlation')\n",
    "    pairs = [(\"True\", \"False\")]\n",
    "    annotate_plot(x=cor_df['Is_Cor_Positive'],\n",
    "                y=np.abs(cor_df['Pearson_Cor']),\n",
    "                ax=axes[3],\n",
    "                pairs=pairs)\n",
    "\n",
    "    fig.savefig(out_file_name)\n",
    "\n",
    "def plot_correlation_comparison(cor_df,\n",
    "                                fig_out_file_name):\n",
    "    cor_df.set_index('Gene', drop=False, inplace=True)\n",
    "    result_analyzer._attach_devlevel_annotated(cor_df)\n",
    "\n",
    "    col_names = ['Pearson_Cor', 'Peason_P_Value', 'length'] # There is a typo\n",
    "    y_label = ['Pearson Correlation', '-Log10(pValue)', 'Number of Pathways']\n",
    "    fig, axes = set_up_subplots(nrow=1, ncols=len(col_names))\n",
    "    plt.subplots_adjust(left=0.035)\n",
    "    for i in range(len(col_names)):\n",
    "        print('Plot: ' + col_names[i])\n",
    "        y = col_names[i]\n",
    "        if y.endswith('P_Value'):\n",
    "            y = -np.log10(cor_df[y])\n",
    "        # Plot numbers of pathways\n",
    "        g = sns.boxplot(y = y,\n",
    "                        x = 'Annotated',\n",
    "                        data = cor_df,\n",
    "                        hue='Tdark',\n",
    "                        ax = axes[i])\n",
    "        g.set_ylabel(y_label[i])\n",
    "        pairs = [((True, False), (True, True)),\n",
    "                ((False, False), (False, True)),\n",
    "                ((False, False), (True, False)),\n",
    "                ((False, True), (True, True))]\n",
    "        annotator = Annotator(y = y,\n",
    "                        x = 'Annotated',\n",
    "                        data = cor_df,\n",
    "                        hue='Tdark',\n",
    "                        ax = axes[i],\n",
    "                        pairs=pairs)\n",
    "        annotator.configure(test='Mann-Whitney', verbose=True)\n",
    "        annotator.apply_and_annotate()\n",
    "    fig.savefig(fig_out_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966f16ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot enrichment score\n",
    "fig_file_name = dir_name + \"/df_cor_fdr_bigscale_113022_dist.pdf\"\n",
    "plot_correlation_distribution(df_cor_fdr_bigscale, fig_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85977e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_out_file_name = dir_name + '/df_cor_fdr_bigscale_113022_comparison.pdf'\n",
    "plot_correlation_comparison(df_cor_fdr_bigscale, fig_out_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e946b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for average_activation\n",
    "fig_out_file_name = dir_name + '/df_cor_average_activation_bigscale_113022_dist.pdf'\n",
    "plot_correlation_distribution(df_cor_average_activation_bigscale, fig_out_file_name)\n",
    "fig_out_file_name = dir_name + '/df_cor_average_activation_bigscale_113022_comparson.pdf'\n",
    "plot_correlation_comparison(df_cor_average_activation_bigscale, fig_out_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6417848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for average_inhibition\n",
    "fig_out_file_name = dir_name + '/df_cor_average_inhibition_bigscale_113022_dist.pdf'\n",
    "plot_correlation_distribution(df_cor_average_inhibition_bigscale, fig_out_file_name)\n",
    "fig_out_file_name = dir_name + '/df_cor_average_inhibition_bigscale_113022_comparson.pdf'\n",
    "plot_correlation_comparison(df_cor_average_inhibition_bigscale, fig_out_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879a2b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the similar results for NLP\n",
    "# Load the dataframe\n",
    "def load_nlp_cor_df(file_name):\n",
    "    df_cor_nlp_fdr = pd.read_csv(file_name, sep='\\t')\n",
    "    # Use Impacted_Pathways for length\n",
    "    df_cor_nlp_fdr['length'] = df_cor_nlp_fdr['Impacted_Pathways']\n",
    "    # Need to use the typo\n",
    "    df_cor_nlp_fdr['Peason_P_Value'] = df_cor_nlp_fdr['Pearson_PValue']\n",
    "    df_cor_nlp_fdr['Pearson_Cor'] = df_cor_nlp_fdr['Pearson']\n",
    "    return df_cor_nlp_fdr\n",
    "    \n",
    "file_name = dir_name + '/../nlp_files/FDR_impact_pubmed_score_cor_04272022_0.txt'\n",
    "df_cor_nlp_fdr = load_nlp_cor_df(file_name)\n",
    "fig_out_file_name = dir_name + '/../nlp_files/FDR_impact_pubmed_score_cor_04272022_0_dist.pdf'\n",
    "plot_correlation_distribution(df_cor_nlp_fdr, fig_out_file_name)\n",
    "fig_out_file_name = dir_name + '/../nlp_files/FDR_impact_pubmed_score_cor_04272022_0_comparison.pdf'\n",
    "plot_correlation_comparison(df_cor_nlp_fdr, fig_out_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250fa73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the average activation for nlp\n",
    "file_name = dir_name + '/../nlp_files/Average_Activation_impact_pubmed_score_cor_04272022_0.txt'\n",
    "df_cor_nlp_average_activation = load_nlp_cor_df(file_name)\n",
    "fig_out_file_name = dir_name + '/../nlp_files/Average_Activation_impact_pubmed_score_cor_04272022_0_dist.pdf'\n",
    "plot_correlation_distribution(df_cor_nlp_average_activation, fig_out_file_name)\n",
    "fig_out_file_name = dir_name + '/../nlp_files/Average_Activation_impact_pubmed_score_cor_04272022_0_comparison.pdf'\n",
    "plot_correlation_comparison(df_cor_nlp_average_activation, fig_out_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250fa73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the average inhibition for nlp\n",
    "file_name = dir_name + '/../nlp_files/Average_Inhibition_impact_pubmed_score_cor_04272022_0.txt'\n",
    "df_cor_nlp_average_inhibition = load_nlp_cor_df(file_name)\n",
    "fig_out_file_name = dir_name + '/../nlp_files/Average_Inhibition_impact_pubmed_score_cor_04272022_0_dist.pdf'\n",
    "plot_correlation_distribution(df_cor_nlp_average_inhibition, fig_out_file_name)\n",
    "fig_out_file_name = dir_name + '/../nlp_files/Average_Inhibition_impact_pubmed_score_cor_04272022_0_comparison.pdf'\n",
    "plot_correlation_comparison(df_cor_nlp_average_inhibition, fig_out_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c46812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot out the results using plotly into files.\n",
    "# The following code can be run without running the above cells\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import TopicModelingResultAnalyzer as analyzer\n",
    "importlib.reload(analyzer)\n",
    "dir_name = '/Volumes/ssd/results/reactome-idg/fi-network-ml/impact_analysis/scRNASeq'\n",
    "color_col_names = ['Tdark', 'Annotated']\n",
    "# file_names = ['df_cor_fdr_bigscale_082322.csv', 'df_cor_average_activation_bigscale_082322.csv', 'df_cor_average_inhibition_bigscale_082322.csv']\n",
    "file_names = ['df_cor_fdr_bigscale_113022.csv',\n",
    "              'df_cor_average_activation_bigscale_113022.csv', \n",
    "              'df_cor_average_inhibition_bigscale_110322.csv']\n",
    "for color_col_name in color_col_names:\n",
    "    print('color_col_name: {}'.format(color_col_name))\n",
    "    for file_name in file_names:\n",
    "        print('\\tfile_name: {}'.format(file_name))\n",
    "        analyzer.plot_cor_batch_results(file_name=dir_name + '/' + file_name,\n",
    "                                        sep=',', \n",
    "                                        need_violin_plot=True, \n",
    "                                        mannwhitneyu_test=True, \n",
    "                                        color_col_name=color_col_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('flair')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "986f3f6afe08f2d688d53234c683086f434a856ab496c44e148f45b060779eaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
